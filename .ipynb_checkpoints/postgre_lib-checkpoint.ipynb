{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgre_params():\n",
    "    load_dotenv()\n",
    "    database = os.environ.get('PG_DATABASE')\n",
    "    username = os.environ.get('PG_USERNAME')\n",
    "    password = os.environ.get('PG_PASSWORD')\n",
    "    host = os.environ.get('PG_HOST')\n",
    "    port = os.environ.get('PG_PORT')\n",
    "    return (database, username, password, host, port)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    database, username, password, host, port = get_postgre_params()\n",
    "    conn = psycopg2.connect(database=database,\\\n",
    "                            user=username,\\\n",
    "                            password=password,\\\n",
    "                            host=host,\\\n",
    "                            port=port)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_tables(cursor):\n",
    "    delete_commands = [\"\"\"DROP TABLE IF EXISTS tweets\"\"\",\n",
    "                       \"\"\"DROP TABLE IF EXISTS tweets_staging\"\"\",\n",
    "                       \"\"\"DROP TABLE IF EXISTS countries\"\"\",\n",
    "                       \"\"\"DROP TABLE IF EXISTS users\"\"\",\n",
    "                       \"\"\"DROP TABLE IF EXISTS user_countries\"\"\"]\n",
    "    \n",
    "    for command in delete_commands:\n",
    "        cursor.execute(command)\n",
    "    print(\"Tables dropped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(cursor):\n",
    "\n",
    "    create_commands = [\n",
    "                \"\"\"\n",
    "                CREATE TABLE tweets_staging\n",
    "                (tweet_id VARCHAR(25) NOT NULL PRIMARY KEY,\n",
    "                 author_id VARCHAR(50) NOT NULL,\n",
    "                 tweet TEXT NOT NULL,\n",
    "                 tweet_date DATE,\n",
    "                 country_id VARCHAR(25));\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                CREATE TABLE tweets\n",
    "                (tweet_id VARCHAR(25) NOT NULL,\n",
    "                 author_id VARCHAR(50) NOT NULL,\n",
    "                 tweet TEXT NOT NULL,\n",
    "                 tweet_date DATE,\n",
    "                 country_id VARCHAR(25));\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                CREATE TABLE countries\n",
    "                (country_id VARCHAR(2) PRIMARY KEY,\n",
    "                 country_name VARCHAR(50) NOT NULL,\n",
    "                 latitude decimal,\n",
    "                 longitude decimal);\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                CREATE TABLE users\n",
    "                (user_id VARCHAR(50) NOT NULL PRIMARY KEY,\n",
    "                 user_name VARCHAR(50));\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                CREATE TABLE user_countries\n",
    "                (user_id VARCHAR(50) NOT NULL,\n",
    "                 country_id VARCHAR(50) NOT NULL);\n",
    "                \"\"\"]\n",
    "    for command in create_commands:\n",
    "        cursor.execute(command)\n",
    "    print(\"Tables created successfully\")\n",
    "    #cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_records(cursor, table_name, records):\n",
    "    for record in records:\n",
    "        query = \"INSERT INTO {} VALUES {};\".format(table_name, record)\n",
    "        cursor.execute(query)\n",
    "    print(\"Records inserted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_records(cursor):\n",
    "    query = \"\"\"\n",
    "            INSERT INTO tweets t\n",
    "            VALUES (select * from tweets_staging) s\n",
    "            ON CONFLICT (t.tweet_id) DO\n",
    "            UPDATE SET t.tweet_date = s.tweet_date\n",
    "            \"\"\"\n",
    "    #for command in create_commands:\n",
    "    cursor.execute(query)\n",
    "    print(\"Merged successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(cursor, table_name, columns = \"*\", condition = \"1=1\"):\n",
    "    query = \"SELECT {} FROM {} WHERE {}\".format(columns, table_name, condition)\n",
    "    cursor.execute(query)\n",
    "    records = cursor.fetchall()\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_postgre():\n",
    "    conn = connect()\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "    return (conn, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_sql_connector(spark, tablename):\n",
    "    database, username, password, host, port = get_postgre_params()\n",
    "    sqldf = spark.read.format(\"jdbc\").\\\n",
    "            options(\n",
    "            url=host, \n",
    "            dbtable=tablename,\n",
    "            user=username,\n",
    "            password=password,\n",
    "            driver='org.postgresql.Driver').load()\n",
    "    return sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook postgre_lib.ipynb to script\n",
      "[NbConvertApp] Writing 4067 bytes to postgre_lib.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script postgre_lib.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
